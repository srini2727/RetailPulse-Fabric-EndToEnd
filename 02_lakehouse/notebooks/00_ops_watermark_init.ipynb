from pyspark.sql import functions as F

spark.sql("""
CREATE TABLE IF NOT EXISTS ops_watermark (
  table_name STRING,
  last_modified_ts TIMESTAMP,
  updated_at TIMESTAMP
)
USING delta
""")

# initialize rows ONLY if table is empty
wm = spark.table("ops_watermark").limit(1)
is_empty = wm.count() == 0

if is_empty:
    init = [
        ("customers",   "1900-01-01 00:00:00"),
        ("orders",      "1900-01-01 00:00:00"),
        ("order_items", "1900-01-01 00:00:00"),
        ("payments",    "1900-01-01 00:00:00"),
        ("inventory",   "1900-01-01 00:00:00"),
        ("returns",     "1900-01-01 00:00:00"),
    ]

    df = (spark.createDataFrame(init, ["table_name","ts_str"])
            .withColumn("last_modified_ts", F.to_timestamp("ts_str"))
            .withColumn("updated_at", F.current_timestamp())
            .drop("ts_str"))

    df.write.mode("append").format("delta").saveAsTable("ops_watermark")

display(spark.table("ops_watermark").orderBy("table_name"))
